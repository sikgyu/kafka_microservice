version: "3.3"
services:
  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper
    restart: always
    ports:
      - "2181"
    hostname: zookeeper
    # create directory /home/<username>/zookeeper/data
    volumes:
      - /home/azureuser/zookeeper/data:/opt/zookeeper-3.4.13/data
  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    ports:
      - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "events:1:1" # topic:partition:replicas
      KAFKA_ADVERTISED_HOST_NAME: sean-kafka.eastus2.cloudapp.azure.com # docker-machine ip
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://sean-kafka.eastus2.cloudapp.azure.com:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/kafka-logs
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      # create /home/<username>/kafka
      - /home/azureuser/kafka:/kafka/kafka-logs
    depends_on:
      - "zookeeper"
  db:
    container_name: mysql
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: "events"
      # So you don't have to use root, but you can if you like
      MYSQL_USER: "user"
      # You can use whatever password you like
      MYSQL_PASSWORD: "password"
      # Password for root access
      MYSQL_ROOT_PASSWORD: "password"
    ports:
      # <Port exposed> : < MySQL Port running inside container>
      - "3306:3306"
    expose:
      # Opens port 3306 on the container
      - "3306"
      # Where our data will be persisted
    volumes:
      - my-db:/var/lib/mysql
  receiver:
    container_name: receiver
    image: receiver:latest
    restart: always
    ports:
      - "8080"
    networks:
      - "api.network"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/receiver:/config
      - /home/azureuser/logs:/logs
    depends_on:
      - "kafka"
  storage:
    container_name: storage
    image: storage:latest
    restart: always
    ports:
      - "8090"
    networks:
      - "api.network"
    depends_on:
      - "kafka"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/storage:/config
      - /home/azureuser/logs:/logs
  processing:
    container_name: processing
    image: processing:latest
    restart: always
    ports:
      - "8100"
    networks:
      - "api.network"
    depends_on:
      - "storage"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/processing:/config
      - /home/azureuser/logs:/logs
      - processing-db:/data
  audit_log:
    container_name: audit
    image: audit_log:latest
    restart: always
    ports:
      - "8110"
    networks:
      - "api.network"
    depends_on:
      - "kafka"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/audit_log:/config
      - /home/azureuser/logs:/logs
  dashboard-ui:
    container_name: dashboard
    image: dashboard-ui:latest
    ports:
      - "3000"
    networks:
      - "api.network"
    depends_on:
      - "processing"
      - "audit_log"
  nginx:
    container_name: nginx
    image: nginx:latest
    # Connects the conf file of the container to the conf file in our folder
    restart: always
    volumes:
      - /home/azureuser/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      # It will start up the nginx only when all api containers have started
    depends_on:
      - "receiver"
      - "storage"
      - "processing"
      - "audit_log"
      - "dashboard-ui"
    # Connects the port 80 of the nginx container to localhost:80 or localhost
    ports:
      - "80:80"
    networks:
      - "api.network"
volumes:
  my-db:
  processing-db:
  
networks:
  api.network: